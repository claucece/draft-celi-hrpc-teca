



Human Rights Protocol Considerations                             S. Celi
Internet-Draft                                                     Brave
Intended status: Informational                           3 November 2025
Expires: 7 May 2026


             Technology-Enabled Child Abuse Considerations
                      draft-celi-hrpc-teca-latest

Abstract

   TODO Abstract

About This Document

   This note is to be removed before publishing as an RFC.

   The latest revision of this draft can be found at
   https://claucece.github.io/draft-celi-hrpc-teca/draft-celi-hrpc-
   teca.html.  Status information for this document may be found at
   https://datatracker.ietf.org/doc/draft-celi-hrpc-teca/.

   Discussion of this document takes place on the Human Rights Protocol
   Considerations Research Group mailing list (mailto:hrpc@irtf.org),
   which is archived at https://mailarchive.ietf.org/arch/browse/hrpc.
   Subscribe at https://www.ietf.org/mailman/listinfo/hrpc/.

   Source for this draft and an issue tracker can be found at
   https://github.com/claucece/draft-celi-hrpc-teca.

Status of This Memo

   This Internet-Draft is submitted in full conformance with the
   provisions of BCP 78 and BCP 79.

   Internet-Drafts are working documents of the Internet Engineering
   Task Force (IETF).  Note that other groups may also distribute
   working documents as Internet-Drafts.  The list of current Internet-
   Drafts is at https://datatracker.ietf.org/drafts/current/.

   Internet-Drafts are draft documents valid for a maximum of six months
   and may be updated, replaced, or obsoleted by other documents at any
   time.  It is inappropriate to use Internet-Drafts as reference
   material or to cite them other than as "work in progress."

   This Internet-Draft will expire on 7 May 2026.

Copyright Notice

   Copyright (c) 2025 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to BCP 78 and the IETF Trust's Legal
   Provisions Relating to IETF Documents (https://trustee.ietf.org/
   license-info) in effect on the date of publication of this document.
   Please review these documents carefully, as they describe your rights
   and restrictions with respect to this document.

Table of Contents

   1.  Introduction
   2.  Conventions and Definitions
     2.1.  Definition and Scope
     2.2.  Common Tactics
   3.  Threat Model
   4.  Security Considerations
   5.  IANA Considerations
   6.  Normative References
   Acknowledgments
   Author's Address

1.  Introduction

   Digital technologies shape how children learn, communicate, and play.
   However, the same technologies can be misused to enable coercion,
   surveillance, manipulation, or exploitation of minors by adults or
   peers.  This document refers to this as technology-enabled child
   abuse (TECA).  It includes but is not limited to physical, emotional,
   or sexual abuse facilitated through digital means.

   While most discussions of technology and children focus on content
   exposure or privacy compliance, technology-enabled abuse encompasses
   broader dynamics of control, dependency, and data exploitation that
   can occur within families, institutions, or online environments.

2.  Conventions and Definitions

   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
   "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
   "OPTIONAL" in this document are to be interpreted as described in
   BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all
   capitals, as shown here.

2.1.  Definition and Scope

   Technology-enabled child abuse refers to any use of digital systems,
   connected devices, or online services to facilitate or intensify the
   abuse, control, or exploitation of a minor.  This includes acts by:

   *  Parents, guardians, or relatives, who may misuse technology to
      monitor or punish.

   *  Teachers, coaches, or institutional staff, who may use
      surveillance or communication tools coercively.

   *  Peers, who may engage in bullying, extortion, or harassment.

   *  Unknown adults or organized groups, who exploit online platforms
      for grooming, manipulation, or trafficking.

2.2.  Common Tactics

   The following categories illustrate—but are not limited to—how
   technology can be used to perpetrate abuse against children.

   1.  Surveillance and Monitoring

   *  Use of “parental control” or monitoring apps beyond protective
      intent, tracking all communications, locations, and activities.

   *  Smart home devices (cameras, speakers, TVs) used to overhear
      conversations or monitor behavior.

   *  Misuse of educational software or school-issued devices to surveil
      students beyond pedagogical purposes.

   *  Exploitation of IoT toys, GPS watches, or “child safety” trackers
      that upload location or voice data without consent.

   1.  Coercion and Manipulation

   *  Forcing children to disclose passwords, messages, or photos under
      threat or punishment.

   *  Coercive use of digital punishments (revoking device access,
      social isolation, public shaming via social media).

   *  Algorithmic manipulation, such as exploiting content
      recommendation systems to isolate a child or feed fear/shame
      narratives.

   1.  Exposure and Exploitation

   *  Coerced creation or sharing of intimate images ("self-generated
      CSAM").

   *  Non-consensual sharing of private photos or videos to humiliate or
      blackmail.

   *  Identity misuse—adults impersonating peers or friends to gain
      trust.

   *  Manipulation through "challenge" trends, games, or encrypted
      messaging for grooming purposes.

   1.  Peer Abuse and Cyberbullying

   *  Continuous online harassment via group chats, gaming platforms, or
      social networks.

   *  Amplification by algorithms that surface humiliating or harmful
      content.

   *  Use of AI tools (e.g., deepfakes) to fabricate compromising images
      or videos.

   1.  Institutional or Systemic Abuse

   *  School or platform data collection without transparency—creating
      lifelong digital traces exploitable for discrimination.

   *  Excessive logging and analytics on minors’ browsing or app use.

   *  Outsourced content moderation or “child safety” systems that
      process minors’ data at large scale without robust safeguards.

3.  Threat Model

   From a security and privacy standpoint, these attacks differ from
   classical adversaries:

   *  The attacker often has legitimate authority or proximity (parent,
      teacher, platform operator).

   *  The child has limited agency to modify configurations, consent to
      data sharing, or understand consequences.

   *  Asymmetric power defines the relationship; coercion and dependency
      replace traditional financial or computational asymmetries.

   *  Attack vectors include shared accounts, school or family networks,
      IoT ecosystems, and devices nominally "for protection".

4.  Security Considerations

   TODO Security

5.  IANA Considerations

   This document has no IANA actions.

6.  Normative References

   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
              Requirement Levels", BCP 14, RFC 2119,
              DOI 10.17487/RFC2119, March 1997,
              <https://www.rfc-editor.org/rfc/rfc2119>.

   [RFC8174]  Leiba, B., "Ambiguity of Uppercase vs Lowercase in RFC
              2119 Key Words", BCP 14, RFC 8174, DOI 10.17487/RFC8174,
              May 2017, <https://www.rfc-editor.org/rfc/rfc8174>.

Acknowledgments

   TODO acknowledge.

Author's Address

   Sofia Celi
   Brave
   Email: cherenkov@riseup.net
